{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f7b167",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummarizer\u001b[49m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mverison\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summarizer' is not defined"
     ]
    }
   ],
   "source": [
    "summarizer --verison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928351c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x7f17de3c1200> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msummarizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Summarizer\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m Summarizer()\n\u001b[1;32m      4\u001b[0m nlp\u001b[38;5;241m.\u001b[39madd_pipe(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentencizer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/summarizer/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msummarizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_processors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Summarizer, TransformerSummarizer\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/summarizer/model_processors.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msummarizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_features\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClusterFeatures\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msummarizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentence_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceHandler\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModelProcessor\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m     13\u001b[0m     aggregate_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmin,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmax\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     22\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-large-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m         random_state: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12345\u001b[39m\n\u001b[1;32m     29\u001b[0m     ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/summarizer/model_processors.py:27\u001b[0m, in \u001b[0;36mModelProcessor\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModelProcessor\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m     13\u001b[0m     aggregate_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmin,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmax\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     22\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-large-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m         custom_model: PreTrainedModel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m         custom_tokenizer: PreTrainedTokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m         hidden: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     26\u001b[0m         reduce_option: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m---> 27\u001b[0m         sentence_handler: SentenceHandler \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     28\u001b[0m         random_state: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12345\u001b[39m\n\u001b[1;32m     29\u001b[0m     ):\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m        This is the parent Bert Summarizer model. New methods should implement this class\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m        :param random_state: The random state to reproduce summarizations.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(random_state)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/summarizer/sentence_handler.py:10\u001b[0m, in \u001b[0;36mSentenceHandler.__init__\u001b[0;34m(self, language)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, language\u001b[38;5;241m=\u001b[39mEnglish):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlp \u001b[38;5;241m=\u001b[39m language()\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentencizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py:779\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    777\u001b[0m     bad_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(factory_name)\n\u001b[1;32m    778\u001b[0m     err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE966\u001b[38;5;241m.\u001b[39mformat(component\u001b[38;5;241m=\u001b[39mbad_val, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    780\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m factory_name\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names:\n",
      "\u001b[0;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x7f17de3c1200> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from summarizer import Summarizer\n",
    "model = Summarizer()\n",
    "# nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"book.txt\", \"r\", encoding='utf-8-sig') as f:\n",
    "    string = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4f0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=model(string)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
