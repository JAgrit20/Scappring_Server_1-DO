{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bccdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8.1\n",
      "  Downloading gensim-3.8.1.tar.gz (23.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.1) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.1) (1.9.3)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/lib/python3/dist-packages (from gensim==3.8.1) (1.16.0)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==3.8.1) (5.2.1)\n",
      "Building wheels for collected packages: gensim\n",
      "  Building wheel for gensim (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gensim: filename=gensim-3.8.1-cp310-cp310-linux_x86_64.whl size=24693403 sha256=cdd2d408d87dfb3663614cbf77fbc84a4cd3070659a953ce71b25f0d67145781\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/9e/24/70d897e629397430e29d85dd5235f448b2cca652c56d9d6992\n",
      "Successfully built gensim\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-3.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim==3.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284dabf2",
   "metadata": {},
   "source": [
    "text=\"\"\"A vaccine for the coronavirus will likely be ready by early 2021 but rolling it out safely across India’s 1.3 billion people will be the country’s biggest challenge in fighting its surging epidemic, a leading vaccine scientist told Bloomberg.\n",
    "India, which is host to some of the front-runner vaccine clinical trials, currently has no local infrastructure in place to go beyond immunizing babies and pregnant women, said Gagandeep Kang, professor of microbiology at the Vellore-based Christian Medical College and a member of the WHO’s Global Advisory Committee on Vaccine Safety.\n",
    "The timing of the vaccine is a caontentious subject around the world. In the U.S., President Donald Trump has contradicted a top administration health expert by saying a vaccine would be available by October. In India, Prime Minister Narendra Modi’s government had promised an indigenous vaccine as early as mid-August, a claim the government and its apex medical research body has since walked back.\n",
    "\"\"\"\n",
    "from collections.abc import Mapping\n",
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "# Summarize text using gensim\n",
    "gen_summary=summarize(text)\n",
    "print(gen_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d8754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top20=[\"‘A Discourse Concerning the Origin and Progress of.pdf\",\"‘Among School Children’.pdf\",\"‘Gerontion’,.pdf\",\"‘La Belle.pdf\",\"‘Leda and the Swan.pdf\",\"‘Of truth’.pdf\",\"‘Sailing to Byzantium’,.pdf\",\"‘The Canonisation.pdf\",\"‘The Dicing’.pdf\",\"‘The Love Song of J. Alfred Prufrock’.pdf\",\"‘The Sunne Rising’.pdf\",\"‘The Vanity of Human Wishes’.pdf\",\"“Porphyria’s Lover”.pdf\",\"2.PDF\",\"119-2014-02-19-2. Wordsworth.Tintern Abbey (bilingual).pdf\",\"1401-407-The Rover Script.pdf\",\"2015.475781.Two-Cheers_text.pdf\",\"4245coleridgedejection.pdf\",\"30827_modestproposal.pdf\",\"A Clean, Well-Lighted Place.pdf\"]\n",
    "all_pdf = [\"‘A Discourse Concerning the Origin and Progress of.pdf\",\"‘Among School Children’.pdf\",\"‘Gerontion’,.pdf\",\"‘La Belle.pdf\",\"‘Leda and the Swan.pdf\",\"‘Of truth’.pdf\",\"‘Sailing to Byzantium’,.pdf\",\"‘The Canonisation.pdf\",\"‘The Dicing’.pdf\",\"‘The Love Song of J. Alfred Prufrock’.pdf\",\"‘The Sunne Rising’.pdf\",\"‘The Vanity of Human Wishes’.pdf\",\"“Porphyria’s Lover”.pdf\",\"2.PDF\",\"119-2014-02-19-2. Wordsworth.Tintern Abbey (bilingual).pdf\",\"1401-407-The Rover Script.pdf\",\"2015.475781.Two-Cheers_text.pdf\",\"4245coleridgedejection.pdf\",\"30827_modestproposal.pdf\",\"A Clean, Well-Lighted Place.pdf\",\"A country.pdf\",\"A Vindication of the Rights of Woman.pdf\",\"amoretti.pdf\",\"An Apology for Poetry.pdf\",\"antony-and-cleopatra_.pdf\",\"aristophanes.lysistrata.pdf\",\"Aristotle, Poetics.pdf\",\"Asimov - Foundation.pdf\",\"Astrophel and Stella.pdf\",\"as-you-like-it_PDF_FolgerShakespeare.pdf\",\"Batter my heart.pdf\",\"Bharata, Natyashastra.pdf\",\"Cheever_Swimmer.pdf\",\"composed-upon-westminster-bridge.pdf\",\"Crime and Punishment.pdf\",\"Culture and Anarchy.pdf\",\"Death be not Proud.pdf\",\"Decolonising the mind.pdf\",\"Denys Thompson and E.R. Leavis,.pdf\",\"DhaulibyJayantaMahapatra.docx\",\"Doctor Faustus.pdf\",\"Draupadi_The_Early_Feminist.pdf\",\"Elegy Written in a Country Churchyard.pdf\",\"EliotTSSweeneyAmongNightingalesNB.1918-19.pdf\",\"ENGL404-Shelley-Hymn-to-Intellectual-Beauty.pdf\",\"ENGL404-Shelley-Ode-to-the-West-Wind.pdf\",\"EnterprisebyNissimEzekiel.docx\",\"Fanon_Frantz_Black_Skin_White_Masks_1986.pdf\",\"Fathers and Sons.pdf\",\"Fra Lippo Lippi.pdf\",\"francisba Of Marriage and Single Life.pdf\",\"FROM RUSSIA WITH LOVE.pdf\",\"G.M.Muktiboth, “The Void” ,“So Very Far”.pdf\",\"Gabriel Garcia Marquez, the Nobel Prize Acceptance Speech.pdf\",\"george-henry_ode-to-liberty-1877.pdf\",\"Goldsmith_Deserted_Village.pdf\",\"Gone with the Wind.pdf\",\"GraysCat.pdf\",\"gullivers-travels.pdf\",\"HALFWAY HOUSE.pdf\",\"Hunger.pdf\",\"J._Dryden_-_MacFlecknoe.pdf\",\"Jane Eyre.pdf\",\"Johnson---London.pdf\",\"Keats_Chapmans_Homer.pdf\",\"Kubla Khan.pdf\",\"Lady of Shallot.pdf\",\"lettersofjohnkea00keatiala.pdf\",\"Leviathan.pdf\",\"london.pdf\",\"Madame Bovary.pdf\",\"Marx-MarxEngels.pdf\",\"medea.pdf\",\"My Last Duchess.pdf\",\"Namvar Singh, ‘Decolonising the Indian Mind’.pdf\",\"Nissim Ezekiel_Night of the Scorpion.pdf\",\"No Second Troy.pdf\",\"Ode To A Nightingale.pdf\",\"Ode.pdf\",\"Of Studies.pdf\",\"Old Goriot.pdf\",\"On His Mistress Going to Bed.pdf\",\"oration_on_the_dignity_of_man.pdf\",\"Othello.pdf\",\"ParadiseLostBk1.pdf\",\"pdfslide.net_the-courter-by-salman-rushdie.pdf\",\"poem-2-goodbye-party-for-miss-pushpa-t-s.pdf\",\"PoliticsandEngLang.pdf\",\"Predestination and Free Will.pdf\",\"Preface to Lyrical Ballads.pdf\",\"Rajaji-Mahabharata.pdf\",\"Salman Rushdie.pdf\",\"Shelley-1818 Frankenstein.pdf\",\"Sigmund Freud, ‘Theory of Dreams’, ‘Oedipus Complex’ and ‘The Structure of the.pdf\",\"SRI SRI.ppsx\",\"T. S. Eliot. ‘Tradition and the Individual Talent’,.pdf\",\"T.S.Eliot-Marina-1-1.pdf\",\"Tagore-Nationalism-1915.pdf\",\"The Courtier on the.pdf\",\"The Defence of Lucknow.pdf\",\"The Descent of Man.pdf\",\"The Door of Opportunity’.pdf\",\"The Duchess of Malfi.pdf\",\"The Garden of Love.pdf\",\"The Goblin Market.pdf\",\"The Holy Bible,.pdf\",\"The Illiad (Penguin).pdf\",\"The Lamb.pdf\",\"The Last Ride Together.pdf\",\"The Mill on the Floss.pdf\",\"The Myth.pdf\",\"The Prince.pdf\",\"The Rape of the Lock.pdf\",\"The Redress of Poetry.pdf\",\"THE REPUBLIC.pdf\",\"The Second Coming.pdf\",\"The Shadow Lines ( PDFDrive.com ).pdf\",\"The Subjection of Women.pdf\",\"The Tyger poem and interp.pdf\",\"The Wife of Bath’s Tale.pdf\",\"the_complete_english_tradesman_by_daniel_defoe.pdf\",\"The_Hollow_Men_by_T._S._Eliot.pdf\",\"The-Crack-Up-Extract.pdf\",\"the-dream-of-a-common-language-adrienne-rich.pdf\",\"the-loom-of-time.pdf\",\"The-PowerandtheGlory.pdf\",\"Therese Raquin.pdf\",\"Things Fall Apart.pdf\",\"THROUGH THE.pdf\",\"To Autumn by John Keats - Poetry Foundation.pdf\",\"Transition_from_a_Despotic_Racism_to_a_Chaotic_Fre.pdf\",\"Ulysses.pdf\",\"Unconfirmed 572726.crdownload.zip\",\"Waiting-for-Godot.pdf\",\"William_Faulkner.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f858e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    " \n",
    "# current working directory\n",
    "print(pathlib.Path().absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271f4f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG 236A (Fall 2015) Dr. Cox \n",
      "1 \n",
      " \n",
      "From  A Discourse Concerning the Original and Progress of Satire (1693)1 \n",
      "By John Dryden \n",
      " \n",
      "[The Art of Satire] \n",
      " \n",
      "* * * How easie it is to call Rogue and Villain, and that wittily? But how hard to make a Man \n",
      "appear a Fool, a Blockhead, or a Knave, without using any of those opprobrious terms? To spare \n",
      "the grossness of the Names, and to do the thing yet more severely, is to draw a full Face, and to \n",
      "make the Nose and Cheeks stand out, and yet not to employ any depth of Shadowing. This is the \n",
      "Mystery of that Noble Trade; which yet no Master can teach to his Apprentice: He may give the \n",
      "Rules, but the Scholar is never the nearer in his practice. Neither is it true, that this fineness of \n",
      "Raillery is offensive. A witty Man is tickl'd while he is hurt in this manner and a Fool feels it not. \n",
      "The occasion of an Offence may possibly be given, but he cannot take it. If it be granted that in \n",
      "effect this way does more Mischief; that a Man is secretly wounded, and though he be not \n",
      "sensible himself, yet the malicious World will find it for him: Yet there is still a vast difference \n",
      "betwixt the slovenly Butchering of a Man, and the fineness of a stroak that separates the Head \n",
      "from the Body, and leaves it standing in its place. A man may be capable, as Jack Ketche's Wife \n",
      "said of his Servant, of a plain piece of Work, a bare Hanging; but to make a Malefactor die \n",
      "sweetly, was only belonging to her Husband. I wish I cou'd apply it to my self, if the Reader \n",
      "wou'd be kind enough to think it belongs to me. The Character of Zimri in my Absalom, is, in \n",
      "my Opinion, worth the whole Poem: 'Tis not bloody, but 'tis ridiculous enough. And he for \n",
      "whom it was intended, was too witty to resent it as an injury. If I had rail'd, I might have suffer'd \n",
      "for it justly: But I manag'd my own Work more happily, perhaps more dextrously. I avoided the \n",
      "mention of great Crimes, and apply'd my self to the representing of Blind-sides, and little \n",
      "Extravagancies: To which, the wittier a Man is, he is generally the more obnoxious. It succeeded \n",
      "as I wish'd; the Jest went round, and he was laught at in his turn who began the Frolick. * * * \n",
      "                                                           \n",
      "1 Text in public domain. Excerpt chosen with reference to the Norton Anthology of British Literature, \n",
      "Volume C. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "doc = fitz.open(top20[0])\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text+=page.get_text()\n",
    "print(text)\n",
    "content = text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ce87a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "T5_PATH = 't5-large' # T5 model name\n",
    "\n",
    "# initialize the model architecture and weights\n",
    "\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained(T5_PATH)\n",
    "\n",
    "# initialize the model tokenizer\n",
    "\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(T5_PATH)\n",
    "\n",
    "inputs = t5_tokenizer.encode(\"summarize: \" + content, return_tensors=\"pt\", max_length=512, padding='max_length', truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0862e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = t5_model.generate(inputs,\n",
    "\n",
    "                                    num_beams=int(2),\n",
    "\n",
    "                                    no_repeat_ngram_size=3,\n",
    "\n",
    "                                    length_penalty=2.0,\n",
    "\n",
    "                                    min_length=100,\n",
    "\n",
    "                                    max_length=200,\n",
    "\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = t5_tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46487b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "036c6d37",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.summarization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summarize\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummarization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keywords\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwikipedia\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim.summarization'"
     ]
    }
   ],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "import wikipedia\n",
    "import en_core_web_sm\n",
    "\n",
    "# Get wiki content.\n",
    "wikisearch = wikipedia.page(\"Amitabh Bachchan\")\n",
    "wikicontent = wikisearch.content\n",
    "nlp = en_core_web_sm.load()\n",
    "doc = nlp(wikicontent)\n",
    "\n",
    "# Save the wiki content to a file\n",
    "# (for reference).\n",
    "f = open(\"wikicontent.txt\", \"w\")\n",
    "f.write(wikicontent)\n",
    "f.close()\n",
    "\n",
    "# Summary (0.5% of the original content).\n",
    "summ_per = summarize(wikicontent, ratio = 0.05)\n",
    "print(\"Percent summary\")\n",
    "print(summ_per)\n",
    "\n",
    "# Summary (200 words)\n",
    "summ_words = summarize(wikicontent, word_count = 200)\n",
    "print(\"Word count summary\")\n",
    "print(summ_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34a9d33c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x7f6fb56b0e80> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msummarizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Summarizer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Summarizer()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/summarizer/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msummarizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_processors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Summarizer, TransformerSummarizer\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/summarizer/model_processors.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msummarizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_features\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClusterFeatures\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msummarizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentence_handler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceHandler\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModelProcessor\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m     13\u001b[0m     aggregate_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmin,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmax\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     22\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-large-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m         random_state: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12345\u001b[39m\n\u001b[1;32m     29\u001b[0m     ):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/summarizer/model_processors.py:27\u001b[0m, in \u001b[0;36mModelProcessor\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModelProcessor\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m     13\u001b[0m     aggregate_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmean,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmin,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmedian,\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mmax\n\u001b[1;32m     18\u001b[0m     }\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     22\u001b[0m         model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-large-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m         custom_model: PreTrainedModel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m         custom_tokenizer: PreTrainedTokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     25\u001b[0m         hidden: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     26\u001b[0m         reduce_option: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m---> 27\u001b[0m         sentence_handler: SentenceHandler \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     28\u001b[0m         random_state: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12345\u001b[39m\n\u001b[1;32m     29\u001b[0m     ):\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m        This is the parent Bert Summarizer model. New methods should implement this class\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m        :param random_state: The random state to reproduce summarizations.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m         np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(random_state)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/summarizer/sentence_handler.py:10\u001b[0m, in \u001b[0;36mSentenceHandler.__init__\u001b[0;34m(self, language)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, language\u001b[38;5;241m=\u001b[39mEnglish):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlp \u001b[38;5;241m=\u001b[39m language()\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentencizer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/language.py:779\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    777\u001b[0m     bad_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(factory_name)\n\u001b[1;32m    778\u001b[0m     err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE966\u001b[38;5;241m.\u001b[39mformat(component\u001b[38;5;241m=\u001b[39mbad_val, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    780\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m factory_name\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names:\n",
      "\u001b[0;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x7f6fb56b0e80> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "from summarizer import Summarizer\n",
    "from pprint import pprint\n",
    "\n",
    "model = Summarizer()\n",
    "result = model(content, num_sentences=5, min_length=60)\n",
    "full = ''.join(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
